{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2: Collaborative filtering\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I like what you like\n",
    "\n",
    "We are going to start our exploration of data mining by looking at recommendation systems. \n",
    "Recommendation systems are everywhere—from Amazon to last.fm recommending music or concerts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Amazon example, above, Amazon combines two bits of information to make a \n",
    "recommendation. The first is that I viewed The Lotus Sutra translated by Gene Reeves; the \n",
    "second, that customers who viewed that translation of the Lotus Sutra also viewed several \n",
    "other translations. \n",
    "The recommendation method we are looking at in this chapter is called collaborative \n",
    "filtering. It's called collaborative because it makes recommendations based on other people—\n",
    "in effect, people collaborate to come up with recommendations. It works like this. Suppose \n",
    "the task is to recommend a book to you. I search among other users of the site to find one \n",
    "that is similar to you in the books she enjoys. Once I find that similar person I can see what \n",
    "she likes and recommend those books to you—perhaps Paolo Bacigalupi's The Windup Girl."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do I find someone who is similar?\n",
    "\n",
    "So the first step is to find someone who is similar. Here's the simple 2D (dimensional) explanation. \n",
    "Suppose users rate books on a 5 star system—zero stars means the book is terrible, 5 stars means the \n",
    "book is great. Because I said we are looking at the simple 2D case, we restrict our ratings to two books: \n",
    "\n",
    "Neal Stephenson's Snow Crash and the Steig Larsson's The Girl with the Dragon Tattoo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, here's a table showing 3 users who rated these books\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I would like to recommend a book to the mysterious Ms. X who rated Snow Crash 4 stars and \n",
    "The Girl with the Dragon Tattoo 2 stars. The first task is to find the person who is most \n",
    "similar, or closest, to Ms. X. I do this by computing distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manhattan Distance\n",
    "The easiest distance measure to compute is what is called Manhattan Distance or cab driver \n",
    "distance. In the 2D case, each person is represented by an (x, y) point. I will add a subscript \n",
    "to the x and y to refer to different people. So (x1, y1) might be Amy and (x2, y2) might be the \n",
    "elusive Ms. X. Manhattan Distance is then calculated by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " x1 - x2| + | y1 - y2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(so the absolute value of the \n",
    "difference between the x values plus \n",
    "the absolute value of the difference \n",
    "between the y values). So the \n",
    "Manhattan Distance for Amy and \n",
    "Ms. X is 4:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing the distance between Ms. X and all three people gives us:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amy is the closest match. We can look in her history and see, for example, that she gave five \n",
    "stars to Paolo Bacigalupi's The Windup Girl and we would recommend that book to Ms. X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidean Distance\n",
    "\n",
    "One benefit of Manhattan Distance is that it is fast to compute. If we are Facebook and are \n",
    "trying to find who among one million users is most similar to little Danny from Kalamazoo, \n",
    "fast is good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pythagorean Theorem\n",
    "\n",
    "You may recall the Pythagorean Theorem from your distant educational past. Here, instead \n",
    "of finding the Manhattan Distance between Amy and Ms. X (which was 4) we are going to \n",
    "figure out the straight line, as-the-crow-flies, distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Pythagorean Theorem tells us how to compute that distance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This straight-line, as-the-crow-flies distance we are calling Euclidean Distance. The formula \n",
    "is\n",
    " Recall that x1 is how well person 1 liked Dragon Tattoo and x2 is how well person 2 liked it; \n",
    "y1 is how well person 1 liked Snow Crash and y2 is how well person 2 liked it.\n",
    "Amy rated both Snow Crash and Dragon Tattoo a 5; The elusive Ms. X rated Dragon Tattoo \n",
    "a 2 and Snow Crash a 4. So the Euclidean distance between \n",
    "Computing the rest of the distances we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-dimensional thinking\n",
    "\n",
    "Let's branch out slightly from just looking at rating two books (and hence 2D) to looking at \n",
    "something slightly more complex. Suppose we work for an online streaming music service \n",
    "and we want to make the experience more compelling by recommending bands. Let's say \n",
    "users can rate bands on a star system 0-5 stars and they can give half star ratings (for \n",
    "example, you can give a band 2.5 stars). The following chart shows 8 users and their ratings \n",
    "of eight bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hyphens in the table indicate that a user didn't rate that particular band. For now we are \n",
    "going to compute the distance based on the number of bands they both reviewed. So, for \n",
    "example, when computing the distance between Angelica and Bill, we will use the ratings for \n",
    "<em>Blues Traveler, Broken Bells, Phoenix, Slightly Stoopid, and Vampire Weekend</em>. So the \n",
    "Manhattan Distance would be:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Manhattan Distance row, the last row of the table, is simply the sum of the differences: \n",
    "(1.5 + 1.5 + 3 + 2 + 1).\n",
    "Computing the Euclidean Distance is similar. We only use the bands the both reviewed:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse that out a bit more:\n",
    "Euclidean = (3.5−2)\n",
    "2\n",
    "+(2− 3.5)\n",
    "2\n",
    "+(5−2)\n",
    "2\n",
    "+(1.5− 3.5)\n",
    "2\n",
    "+(2− 3)\n",
    "2\n",
    "= 1.52\n",
    "+(−1.5)\n",
    "2\n",
    "+ 3\n",
    "2\n",
    "+(−2)\n",
    "2\n",
    "+1\n",
    "2\n",
    "= 2.25+2.25+9+ 4+1\n",
    "= 18.5 = 4.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A flaw\n",
    "\n",
    "It looks like we discovered a flaw with using these distance measures. When we computed the \n",
    "distance between Hailey and Veronica, we noticed they only rated two bands in common \n",
    "(Norah Jones and The Strokes), whereas when we computed the distance between Hailey \n",
    "and Jordyn, we noticed they rated five bands in common. This seems to skew our distance \n",
    "measurement, since the Hailey-Veronica distance is in 2 dimensions while the Hailey-Jordyn\n",
    "distance is in 5 dimensions. Manhattan Distance and Euclidean Distance work best when \n",
    "there are no missing values. Dealing with missing values is an active area of scholarly \n",
    "research. Later in the book we will talk about how to deal with this problem. For now just be \n",
    "aware of the flaw as we continue our first exploration into building a recommendation \n",
    "system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A generalization\n",
    "\n",
    "We can generalize Manhattan Distance and Euclidean Distance to what is called the \n",
    "Minkowski Distance Metric:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When\n",
    "•\n",
    "r = 1: The formula is Manhattan Distance.\n",
    "•\n",
    "r = 2: The formula is Euclidean Distance\n",
    "•\n",
    "r = ∞: Supremum Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you see formulas like this in a book you have \n",
    "several options. One option is to see the formula--\n",
    "brain neurons fire that say math formula--and then \n",
    "you quickly skip over it to the next English bit. I have \n",
    "to admit that I was once a skipper. The other \n",
    "option is to see the formula, pause, and dissect it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many times you’ll find the formula quite understandable. Let’s dissect it now. When r = 1 the \n",
    "formula reduces to Manhattan Distance:\n",
    "\n",
    "\n",
    "d(x,y)= | xk\n",
    "− yk\n",
    "|\n",
    "k=1\n",
    "n\n",
    "∑\n",
    "\n",
    "\n",
    "So for the music example we have been using throughout the chapter, x and y represent two \n",
    "people and d(x, y) represents the distance between them. n is the number of bands they both \n",
    "rated (both x and y rated that band). We’ve done that calculation a few pages back:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That difference column represents the absolute value of the difference and we sum those up \n",
    "to get 9. \n",
    "When r = 2, we get the Euclidean distance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing the data in Python (finally some coding)\n",
    "\n",
    "There are several ways of representing the data in the table above using Python. I am going to \n",
    "use Python's dictionary (also called an associative array or hash table):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0, \n",
    "                      \"Norah Jones\": 4.5, \"Phoenix\": 5.0, \n",
    "                      \"Slightly Stoopid\": 1.5, \n",
    "                      \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0}, \n",
    "         \"Bill\":     {\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5, \n",
    "                      \"Deadmau5\": 4.0, \n",
    "                      \"Phoenix\": 2.0, \"Slightly Stoopid\": 3.5, \n",
    "                      \"Vampire Weekend\": 3.0}, \n",
    "         \"Chan\":     {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0, \n",
    "                      \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \n",
    "                      \"Phoenix\": 5, \"Slightly Stoopid\": 1.0}, \n",
    "         \"Dan\":      {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0, \n",
    "                      \"Deadmau5\": 4.5, \"Phoenix\": 3.0, \n",
    "                      \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \n",
    "                      \"Vampire Weekend\": 2.0}, \n",
    "         \"Hailey\":   {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0, \n",
    "                      \"Norah Jones\": 4.0, \"The Strokes\": 4.0, \n",
    "                      \"Vampire Weekend\": 1.0}, \n",
    "         \"Jordyn\":   {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0, \"Norah Jones\": 5.0, \n",
    "                      \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.5, \n",
    "                      \"The Strokes\": 4.0, \"Vampire Weekend\": 4.0}, \n",
    "         \"Sam\":      {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0, \n",
    "                      \"Norah Jones\": 3.0, \"Phoenix\": 5.0, \n",
    "                      \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0}, \n",
    "         \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0, \n",
    "                      \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5, \n",
    "                      \"The Strokes\": 3.0}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the ratings of a particular user as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blues Traveler': 3.0,\n",
       " 'Norah Jones': 5.0,\n",
       " 'Phoenix': 4.0,\n",
       " 'Slightly Stoopid': 2.5,\n",
       " 'The Strokes': 3.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[\"Veronica\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code to compute Manhattan distance\n",
    "\n",
    "I'd like to write a function that computes the Manhattan distance as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manhattan(rating1, rating2): \n",
    "    \"\"\"Computes the Manhattan distance. Both rating1 and rating2 are \n",
    "    dictionaries of the form {'The Strokes': 3.0, 'Slightly \n",
    "    Stoopid': 2.5}\"\"\"\n",
    "#     import numpy as np\n",
    "#     p1 = np.array(list(rating1.values()))\n",
    "#     p2 = np.array(list(rating2.values()))\n",
    "    \n",
    "#     distance = np.sum(np.abs(p1-p2))\n",
    "    \n",
    "#     return distance\n",
    "    distance = 0 \n",
    "    commonRatings = False\n",
    "\n",
    "    for key in rating1: \n",
    "        if key in rating2: \n",
    "            distance += abs(rating1[key] - rating2[key]) \n",
    "            commonRatings = True\n",
    "    if commonRatings: \n",
    "        return distance \n",
    "    else: \n",
    "        return -1 #Indicates no ratings in common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan(users['Hailey'], users['Veronica']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.5"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manhattan(users['Hailey'], users['Jordyn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a function to find the closest person (actually this returns a sorted list with the closest \n",
    "person first):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nearest_neighbor(username, users):\n",
    "    \"\"\"\n",
    "    creates a sorted list of users based on their distance to username\n",
    "    \"\"\" \n",
    "    distances = [] \n",
    "    for user in users: \n",
    "        if user != username: \n",
    "            distance = manhattan(users[user], users[username]) \n",
    "            distances.append((distance, user)) \n",
    "    # sort based on distance -- closest first\n",
    "    distances.sort() \n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2.0, 'Veronica'),\n",
       " (4.0, 'Chan'),\n",
       " (4.0, 'Sam'),\n",
       " (4.5, 'Dan'),\n",
       " (5.0, 'Angelica'),\n",
       " (5.5, 'Bill'),\n",
       " (7.5, 'Jordyn')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nearest_neighbor('Hailey', users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we are going to put this all together to make recommendations. Let's say I want to \n",
    "make recommendations for Hailey. I find her nearest neighbor—Veronica in this case. I will \n",
    "then find bands that Veronica has rated but Hailey has not. Also, I will assume that Hailey \n",
    "would have rated the bands the same as (or at least very similar to) Veronica. For example, \n",
    "Hailey has not rated the great band Phoenix. Veronica has rated Phoenix a '4' so we will \n",
    "assume Hailey is likely to enjoy the band as well. Here is my function to make \n",
    "recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(username, users):\n",
    "    \"\"\"\n",
    "    Give list of recommendations\n",
    "    \"\"\"\n",
    "    # first find nearest neighbor\n",
    "    nearest = compute_nearest_neighbor(username, users)[0][1] \n",
    "    recommendations = [] \n",
    "    # now find bands neighbor rated that user didn't \n",
    "    neighborRatings = users[nearest] \n",
    "    userRatings = users[username] \n",
    "    for artist in neighborRatings: \n",
    "        if not artist in userRatings:\n",
    "            recommendations.append((artist, neighborRatings[artist]))\n",
    "    recommendations.sort(key=lambda artistTuple: artistTuple[1], reverse = True)\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Phoenix', 4.0), ('Blues Traveler', 3.0), ('Slightly Stoopid', 2.5)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Hailey', users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fits with our expectations. As we saw above, Hailey's nearest neighbor was Veronica and \n",
    "Veronica gave Phoenix a '4'. Let's try a few more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Strokes', 4.0), ('Vampire Weekend', 1.0)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Chan', users) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Deadmau5', 1.0)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Sam', users) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We think Chan will like The Strokes and also predict that Sam will not like Deadmau5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Angelica', users) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm. For Angelica we got back an empty set meaning we have no recommendations for her. \n",
    "Let us see what went wrong:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.5, 'Veronica')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nearest_neighbor('Angelica', users) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Angelica's nearest neighbor is Veronica. When we look at their ratings:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that Angelica rated every band that Veronica did. We have no new ratings, so no \n",
    "recommendations. \n",
    "Shortly, we will see how to improve the system to avoid these cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski(rating1, rating2, r):\n",
    "    \"\"\"\n",
    "    Computes the Minkowski distance. Both rating1 and rating2 are dictionaries of the form \n",
    "    {'The Strokes': 3.0, 'Slightly Stoopid': 2.5}\n",
    "    \"\"\"\n",
    "    distance = 0\n",
    "    commonRatings = False\n",
    "    for key in rating1:\n",
    "        if key in rating2:\n",
    "            #distance += pow(abs(rating1[key] - rating2[key]), r)\n",
    "            distance += abs(rating1[key] - rating2[key])** r\n",
    "            commonRatings = True\n",
    "    if commonRatings:\n",
    "        return distance ** (1/r)\n",
    "    else:\n",
    "        return -1 #Indicates no ratings in common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "user = 'Hailey'\n",
    "username = 'Veronica'\n",
    "distance = minkowski(users[user], users[username], 1)\n",
    "print(distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blame the users\n",
    "Let's take a look at the user ratings in a bit more detail. We see that users have very different \n",
    "behaviors when it comes to rating bands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how do we compare, for example, Hailey to Jordan? Does Hailey's '4' mean the same as \n",
    "Jordyn's '4' or Jordyn's '5'? I would guess it is more like Jordyn's '5'. This variability can \n",
    "create problems with a recommendation system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Correlation Coefficient\n",
    "One way to fix this problem is to use the Pearson Correlation Coefficient. First, the general \n",
    "idea. Consider the following data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of what is called 'grade inflation' in the data mining community. \n",
    "Angelica's lowest rating is 4—all her rating are between 4 and 5. If we are to graph this chart \n",
    "it would look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that this is a straight line indicates a perfect agreement between Angelica and Bill. \n",
    "Both Angelica and Bill rated Phoenix as the best band, Blues Traveler next, Norah Jones after \n",
    "that, and so on. As Angelica and Bill agree less, the less the data points reside on a straight \n",
    "line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So chart-wise perfect agreement is indicated by a straight line. The Pearson Correlation \n",
    "Coefficient is a measure of correlation between two variables (in this specific case the \n",
    "correlation between Angelica and Bill). It ranges between -1 and 1 inclusive. 1 indicates \n",
    "perfect agreement. -1 indicates perfect disagreement. To give you a general feel for this, the \n",
    "chart above with the straight line has a Pearson of 1, the chart above that I labelled ‘pretty \n",
    "good agreement’ has a Pearson of 0.91, and the ‘not so good agreement’ chart has a Pearson \n",
    "of 0.81 So we can use this to find the individual who is most similar to the person we are \n",
    "interested in. \n",
    "The formula for the Pearson Correlation Coefficient is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a personal confession. I have a Bachelor of Fine \n",
    "Arts degree in music. While I have taken courses in \n",
    "ballet, modern dance, and costume design, I did not \n",
    "have a single math course as an undergrad. Before that, I \n",
    "attended an all boys trade high school where I took \n",
    "courses in plumbing and automobile repair, but no \n",
    "courses in math other than the basics. Either due to this \n",
    "background or some innate wiring in my brain, when I \n",
    "read a book that has formulas like the one above, I tend \n",
    "to skip over the formulas and continue with the text \n",
    "below them. If you are like me I would urge you to fight "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that urge and actually look at the formula. Many formulas that on a quick glimpse look \n",
    "complex are actually understandable by mere mortals.\n",
    "Other than perhaps looking complex, the problem with the formula above is that the \n",
    "algorithm to implement it would require multiple passes through the data. Fortunately for us \n",
    "algorithmic people, there is an alternative formula, which is an approximation of Pearson:\n",
    "r =\n",
    "xi\n",
    "yi\n",
    "−\n",
    "xi\n",
    "i=1\n",
    "n\n",
    "∑ yi\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "n\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "xi\n",
    "2\n",
    "i=1\n",
    "n\n",
    "∑ −\n",
    "( xi\n",
    ")\n",
    "2\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "n\n",
    "yi\n",
    "2\n",
    "−\n",
    "( yi\n",
    ")\n",
    "2\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "n\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "(Remember what I said two paragraphs above about not skipping over formulas) This \n",
    "formula, in addition to looking initially horribly complex is, more importantly, numerically \n",
    "unstable meaning that what might be a small error is amplified by this reformulation. The big \n",
    "plus is that we can implement it using a single-pass algorithm, which we will get to shortly. \n",
    "First, let’s dissect this formula and work through the example we saw a few pages back:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pearson(rating1, rating2):\n",
    "    sum_xy = 0 \n",
    "    sum_x = 0 \n",
    "    sum_y = 0 \n",
    "    sum_x2 = 0 \n",
    "    sum_y2 = 0 \n",
    "    n = 0 \n",
    "    for key in rating1: \n",
    "        if key in rating2: \n",
    "            n += 1 \n",
    "            x = rating1[key] \n",
    "            y = rating2[key] \n",
    "            sum_xy += x * y \n",
    "            sum_x += x \n",
    "            sum_y += y \n",
    "            sum_x2 += x**2 \n",
    "            sum_y2 += y**2 \n",
    "    # now compute denominator \n",
    "    denominator = sqrt(sum_x2 - (sum_x**2) / n) * sqrt(sum_y2 -(sum_y**2) / n) \n",
    "    if denominator == 0: \n",
    "        return 0 \n",
    "    else: \n",
    "        return (sum_xy - (sum_x * sum_y) / n) / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9040534990682699"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson(users['Angelica'], users['Bill']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42008402520840293"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson(users['Angelica'], users['Hailey']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7639748605475432"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearson(users['Angelica'], users['Jordyn']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt \n",
    "sqrt(9) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###One last formula – Cosine Similarity\n",
    "\n",
    "I would like to present one last formula, which is very popular in text mining but also used in \n",
    "collaborative filtering—cosine similarity. To see when we might use this formula, let’s say I \n",
    "change my example slightly. We will keep track of the number of times a person played a \n",
    "particular song track and use that information to base our recommendations on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just by eye-balling the above chart (and by using any of the distance formulas mentioned \n",
    "above) we can see that Sally is more similar in listening habits to Ann than Ben is. \n",
    "So what is the problem?\n",
    "I have around four thousand tracks in iTunes. Here is a snapshot of the top few ordered by \n",
    "number of plays:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So my top track is Moonlight Sonata by Marcus Miller with 25 plays. Chances are that you \n",
    "have played that track zero times. In fact, chances are good that you have not played any of \n",
    "my top tracks. In addition, there are over 15 million tracks in iTunes and I have only four \n",
    "thousand. So the data for a single person is sparse since it has relatively few non-zero \n",
    "attributes (plays of a track). When we compare two people by using the number of plays of \n",
    "the 15 million tracks, mostly they will have shared zeros in common. However, we do not \n",
    "want to use these shared zeros when we are computing similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar case can be made when we are comparing text \n",
    "documents using words. Suppose we liked a certain \n",
    "book, say Tom Corbett Space Cadet: The Space Pioneers\n",
    "by Carey Rockwell and we want to find a similar book. \n",
    "One possible way is to use word frequency. The \n",
    "attributes will be individual words and the values of \n",
    "those attributes will be the frequency of those words in \n",
    "the book. So 6.13% of the words in The Space Pioneers\n",
    "are occurrences of the word the, 0.89% are the word \n",
    "Tom, 0.25% of the words are space. I can compute the \n",
    "similarity of this book to others by using these word \n",
    "frequencies. However, the same problem related to \n",
    "sparseness of data occurs here. There are 6,629 \n",
    "unique words in The Space Pioneers and there are a \n",
    "bit over one million unique words in English. So if \n",
    "our attributes are English words, there will be \n",
    "relatively few non-zero attributes for The Space \n",
    "Pioneers or any other book. Again, any measure of similarity should not \n",
    "depend on the shared-zero values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similarity ignores 0-0 matches. It is defined as\n",
    "cos(x,y)=\n",
    "x⋅y\n",
    "x × y\n",
    "where · indicates the dot product and ||x|| indicates the length of the vector x. The length of a \n",
    "vector is\n",
    "xi\n",
    "2\n",
    "i=1\n",
    "n\n",
    "∑\n",
    "For example, suppose my two vectors are\n",
    "x = (4,1,3,5,2)\n",
    "y = (5,2,4,5,1)\n",
    "then\n",
    "x = 4\n",
    "2\n",
    "+1\n",
    "2\n",
    "+ 3\n",
    "2\n",
    "+5\n",
    "2\n",
    "+2\n",
    "2\n",
    "= 55 = 7.416\n",
    "y = 5\n",
    "2\n",
    "+2\n",
    "2\n",
    "+ 4\n",
    "2\n",
    "+5\n",
    "2\n",
    "+1\n",
    "2\n",
    "= 71 = 8.426\n",
    "The dot product is\n",
    "x⋅y = (4×5)+(1×2)+(3× 4)+(5×5)+(2×1)= 61\n",
    "And the cosine similarity is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cos(x,y)=\n",
    "61\n",
    "7.416×8.426\n",
    "=\n",
    "61\n",
    "62.4899\n",
    "= 0.976"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cosine similarity rating ranges from 1 indicated perfect similarity to -1 indicate perfect \n",
    "negative similarity.\n",
    "Which similarity mea35 sure to use?\n",
    "We will be exploring this question throughout the book. For now, here are a few helpful \n",
    "hints:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Weirdnesses\n",
    "\n",
    "Suppose we are trying to make recommendations for Amy who loves Phoenix, Passion Pit \n",
    "and Vampire Weekend. Our closest match is Bob who also loves Phoenix, Passion Pit, and \n",
    "Vampire Weekend. His father happens to play accordion for the Walter Ostanek Band, this \n",
    "year's Grammy winner in the polka category. Because of familial obligations, Bob gives 5 \n",
    "stars to the Walter Ostanek Band. Based on our current recommendation system, we think \n",
    "Amy will absolutely love the band. But common sense tells us she probably won't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or think of Professor Billy Bob Olivera who loves to read data mining books and science \n",
    "fiction. His closest match happens to be me, who also likes data mining books and science \n",
    "fiction. However, I like standard poodles and have rated The Secret Lives of Standard \n",
    "Poodles highly. Our current recommendation system would likely recommend that book to \n",
    "the professor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that we are relying on a single “most similar” person. Any quirk that person \n",
    "has is passed on as a recommendation. One way of evening out those quirks is to base our \n",
    "recommendations on more than one person who is similar to our user. For this we can use \n",
    "the k-nearest neighbor approach. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###K-nearest neighbor\n",
    "\n",
    "In the k-nearest neighbor approach to collaborative filtering we use k most similar people to \n",
    "determine recommendations. The best value for k is application specific—you will need to do \n",
    "some experimentation. Here's an example to give you the basic idea.\n",
    "Suppose I would like to make recommendations for Ann and am using k-nearest neighbor \n",
    "with k=3. The three nearest neighbors and their Pearson scores are shown in the following \n",
    "table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of these three people are going to influence the recommendations. The question is how \n",
    "can I determine how much influence each person should have. If there is a Pie of Influence™, \n",
    "how big a slice should I give each person? If I add up the Pearson scores I get 2. Sally's share \n",
    "is 0.8/2 or 40%. Eric's share is 35% (0.7 / 2) and Amanda's share is 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose Amanda, Eric, and Sally, rated the band, The Grey Wardens as follows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##A New Dataset\n",
    "\n",
    "Ok, it is time to look at a more realistic dataset. Cai-Nicolas Zeigler collected over one million \n",
    "ratings of books from the Book Crossing website. This ratings are of 278,858 users rating \n",
    "271,379 books. This anonymized data is available at http://www.informatik.uni-freiburg.de/\n",
    "~cziegler/BX/ both as an SQL dump and a text file of comma-separated-values (CSV). I had \n",
    "some problems loading this data into Python due to apparent character encoding problems. \n",
    "My fixed version of the CVS files are available on this book's website. \n",
    "\n",
    "The CSV files represent three tables:\n",
    "•\n",
    "BX-Users, which, as the name suggests, contains information about the users. There is an \n",
    "integer user-id field, as well as the location (i.e., Albuquerque, NM) and age. The names \n",
    "have been removed to anonymize the data.\n",
    "•\n",
    "BX-Books. Books are identified by the ISBN, book title, author, year of publication, and \n",
    "publisher.\n",
    "•\n",
    "BX-Book-Ratings, which includes a user-id, book ISBN, and a rating from 0-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = recommender(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Blues Traveler', 5.0)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recommend('Jordyn') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Phoenix', 5.0), ('Slightly Stoopid', 4.5)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recommend('Hailey') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function loadBookDB in the recommender class loads the data from these files.\n",
    "Now I am going to load the book dataset. The argument to the loadBookDB function is the \n",
    "path to the BX book files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r.loadBookDB('/Users/antigen/dev/guide-to-data-mining/BX-Dump')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###FILTERINGDATApearson.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  FILTERINGDATApearson.py\n",
    "#\n",
    "#  Code file for the book Programmer's Guide to Data Mining\n",
    "#  http://guidetodatamining.com\n",
    "#  Ron Zacharski\n",
    "#\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0, \"Norah Jones\": 4.5, \"Phoenix\": 5.0, \"Slightly Stoopid\": 1.5, \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},\n",
    "         \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5, \"Deadmau5\": 4.0, \"Phoenix\": 2.0, \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},\n",
    "         \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0, \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5, \"Slightly Stoopid\": 1.0},\n",
    "         \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0, \"Deadmau5\": 4.5, \"Phoenix\": 3.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 2.0},\n",
    "         \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0, \"Norah Jones\": 4.0, \"The Strokes\": 4.0, \"Vampire Weekend\": 1.0},\n",
    "         \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0, \"Norah Jones\": 5.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 4.0},\n",
    "         \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0, \"Norah Jones\": 3.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},\n",
    "         \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0, \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5, \"The Strokes\": 3.0}\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def manhattan(rating1, rating2):\n",
    "    \"\"\"Computes the Manhattan distance. Both rating1 and rating2 are dictionaries\n",
    "       of the form {'The Strokes': 3.0, 'Slightly Stoopid': 2.5}\"\"\"\n",
    "    distance = 0\n",
    "    total = 0\n",
    "    for key in rating1:\n",
    "        if key in rating2:\n",
    "            distance += abs(rating1[key] - rating2[key])\n",
    "            total += 1\n",
    "    if total > 0:\n",
    "        return distance / total\n",
    "    else:\n",
    "        return -1 #Indicates no ratings in common\n",
    "\n",
    "\n",
    "\n",
    "def pearson(rating1, rating2):\n",
    "    sum_xy = 0\n",
    "    sum_x = 0\n",
    "    sum_y = 0\n",
    "    sum_x2 = 0\n",
    "    sum_y2 = 0\n",
    "    n = 0\n",
    "    for key in rating1:\n",
    "        if key in rating2:\n",
    "            n += 1\n",
    "            x = rating1[key]\n",
    "            y = rating2[key]\n",
    "            sum_xy += x * y\n",
    "            sum_x += x\n",
    "            sum_y += y\n",
    "            sum_x2 += pow(x, 2)\n",
    "            sum_y2 += pow(y, 2)\n",
    "    # now compute denominator\n",
    "    denominator = sqrt(sum_x2 - pow(sum_x, 2) / n) * sqrt(sum_y2 - pow(sum_y, 2) / n)\n",
    "    if denominator == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (sum_xy - (sum_x * sum_y) / n) / denominator\n",
    "            \n",
    "\n",
    "def computeNearestNeighbor(username, users):\n",
    "    \"\"\"creates a sorted list of users based on their distance to username\"\"\"\n",
    "    distances = []\n",
    "    for user in users:\n",
    "        if user != username:\n",
    "            distance = manhattan(users[user], users[username])\n",
    "            distances.append((distance, user))\n",
    "    # sort based on distance -- closest first\n",
    "    distances.sort()\n",
    "    return distances\n",
    "\n",
    "def recommend(username, users):\n",
    "    \"\"\"Give list of recommendations\"\"\"\n",
    "    # first find nearest neighbor\n",
    "    nearest = computeNearestNeighbor(username, users)[0][1]\n",
    "\n",
    "    recommendations = []\n",
    "    # now find bands neighbor rated that user didn't\n",
    "    neighborRatings = users[nearest]\n",
    "    userRatings = users[username]\n",
    "    for artist in neighborRatings:\n",
    "        if not artist in userRatings:\n",
    "            recommendations.append((artist, neighborRatings[artist]))\n",
    "    # using the fn sorted for variety - sort is more efficient\n",
    "    return sorted(recommendations, key=lambda artistTuple: artistTuple[1], reverse = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###FILTERINGDATA.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "#  FILTERINGDATA.py\n",
    "#\n",
    "#  Code file for the book Programmer's Guide to Data Mining\n",
    "#  http://guidetodatamining.com\n",
    "#  Ron Zacharski\n",
    "#\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0, \"Norah Jones\": 4.5, \"Phoenix\": 5.0, \"Slightly Stoopid\": 1.5, \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},\n",
    "         \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5, \"Deadmau5\": 4.0, \"Phoenix\": 2.0, \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},\n",
    "         \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0, \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5, \"Slightly Stoopid\": 1.0},\n",
    "         \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0, \"Deadmau5\": 4.5, \"Phoenix\": 3.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 2.0},\n",
    "         \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0, \"Norah Jones\": 4.0, \"The Strokes\": 4.0, \"Vampire Weekend\": 1.0},\n",
    "         \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0, \"Norah Jones\": 5.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 4.0},\n",
    "         \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0, \"Norah Jones\": 3.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},\n",
    "         \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0, \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5, \"The Strokes\": 3.0}\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "def manhattan(rating1, rating2):\n",
    "    \"\"\"Computes the Manhattan distance. Both rating1 and rating2 are dictionaries\n",
    "       of the form {'The Strokes': 3.0, 'Slightly Stoopid': 2.5}\"\"\"\n",
    "    distance = 0\n",
    "    total = 0\n",
    "    for key in rating1:\n",
    "        if key in rating2:\n",
    "            distance += abs(rating1[key] - rating2[key])\n",
    "            total += 1\n",
    "    if total > 0:\n",
    "        return distance / total\n",
    "    else:\n",
    "        return -1 #Indicates no ratings in common\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def computeNearestNeighbor(username, users):\n",
    "    \"\"\"creates a sorted list of users based on their distance to username\"\"\"\n",
    "    distances = []\n",
    "    for user in users:\n",
    "        if user != username:\n",
    "            distance = manhattan(users[user], users[username])\n",
    "            distances.append((distance, user))\n",
    "    # sort based on distance -- closest first\n",
    "    distances.sort()\n",
    "    return distances\n",
    "\n",
    "def recommend(username, users):\n",
    "    \"\"\"Give list of recommendations\"\"\"\n",
    "    # first find nearest neighbor\n",
    "    nearest = computeNearestNeighbor(username, users)[0][1]\n",
    "\n",
    "    recommendations = []\n",
    "    # now find bands neighbor rated that user didn't\n",
    "    neighborRatings = users[nearest]\n",
    "    userRatings = users[username]\n",
    "    for artist in neighborRatings:\n",
    "        if not artist in userRatings:\n",
    "            recommendations.append((artist, neighborRatings[artist]))\n",
    "    # using the fn sorted for variety - sort is more efficient\n",
    "    return sorted(recommendations, key=lambda artistTuple: artistTuple[1], reverse = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###A Python Recommendation Class\n",
    "\n",
    "I combined some of what we covered in this chapter in a Python Class. Even though it is \n",
    "slightly long I have included the code here (don't forget you can download the code at http://www.guidetodatamining.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs \n",
    "from math import sqrt\n",
    "\n",
    "users = {\"Angelica\": {\"Blues Traveler\": 3.5, \"Broken Bells\": 2.0, \"Norah Jones\": 4.5, \"Phoenix\": 5.0, \"Slightly Stoopid\": 1.5, \"The Strokes\": 2.5, \"Vampire Weekend\": 2.0},\n",
    "         \"Bill\":{\"Blues Traveler\": 2.0, \"Broken Bells\": 3.5, \"Deadmau5\": 4.0, \"Phoenix\": 2.0, \"Slightly Stoopid\": 3.5, \"Vampire Weekend\": 3.0},\n",
    "         \"Chan\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 1.0, \"Deadmau5\": 1.0, \"Norah Jones\": 3.0, \"Phoenix\": 5, \"Slightly Stoopid\": 1.0},\n",
    "         \"Dan\": {\"Blues Traveler\": 3.0, \"Broken Bells\": 4.0, \"Deadmau5\": 4.5, \"Phoenix\": 3.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 2.0},\n",
    "         \"Hailey\": {\"Broken Bells\": 4.0, \"Deadmau5\": 1.0, \"Norah Jones\": 4.0, \"The Strokes\": 4.0, \"Vampire Weekend\": 1.0},\n",
    "         \"Jordyn\":  {\"Broken Bells\": 4.5, \"Deadmau5\": 4.0, \"Norah Jones\": 5.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.5, \"The Strokes\": 4.0, \"Vampire Weekend\": 4.0},\n",
    "         \"Sam\": {\"Blues Traveler\": 5.0, \"Broken Bells\": 2.0, \"Norah Jones\": 3.0, \"Phoenix\": 5.0, \"Slightly Stoopid\": 4.0, \"The Strokes\": 5.0},\n",
    "         \"Veronica\": {\"Blues Traveler\": 3.0, \"Norah Jones\": 5.0, \"Phoenix\": 4.0, \"Slightly Stoopid\": 2.5, \"The Strokes\": 3.0}\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class recommender:\n",
    "\n",
    "    def __init__(self, data, k=1, metric='pearson', n=5):\n",
    "        \"\"\" initialize recommender\n",
    "        currently, if data is dictionary the recommender is initialized to it.\n",
    "        For all other data types of data, no initialization occurs\n",
    "        k is the k value for k nearest neighbor\n",
    "        metric is which distance formula to use\n",
    "        n is the maximum number of recommendations to make\"\"\"\n",
    "        self.k = k\n",
    "        self.n = n\n",
    "        self.username2id = {}\n",
    "        self.userid2name = {}\n",
    "        self.productid2name = {}\n",
    "        # for some reason I want to save the name of the metric\n",
    "        self.metric = metric\n",
    "        if self.metric == 'pearson':\n",
    "            self.fn = self.pearson\n",
    "        #\n",
    "        # if data is dictionary set recommender data to it\n",
    "        #\n",
    "        if type(data).__name__ == 'dict':\n",
    "            self.data = data\n",
    "\n",
    "    def convertProductID2name(self, id):\n",
    "        \"\"\"Given product id number return product name\"\"\"\n",
    "        if id in self.productid2name:\n",
    "            return self.productid2name[id]\n",
    "        else:\n",
    "            return id\n",
    "\n",
    "\n",
    "    def userRatings(self, id, n):\n",
    "        \"\"\"Return n top ratings for user with id\"\"\"\n",
    "        print (\"Ratings for \" + self.userid2name[id])\n",
    "        ratings = self.data[id]\n",
    "        print(len(ratings))\n",
    "        ratings = list(ratings.items())\n",
    "        ratings = [(self.convertProductID2name(k), v) for (k, v) in ratings]\n",
    "        # finally sort and return\n",
    "        ratings.sort(key=lambda artistTuple: artistTuple[1], reverse = True)\n",
    "        ratings = ratings[:n]\n",
    "        for rating in ratings:\n",
    "            print(\"%s\\t%i\" % (rating[0], rating[1]))\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def loadBookDB(self, path=''):\n",
    "        \"\"\"loads the BX book dataset. Path is where the BX files are located\"\"\"\n",
    "        self.data = {}\n",
    "        i = 0\n",
    "        #\n",
    "        # First load book ratings into self.data\n",
    "        #\n",
    "        f = codecs.open(path + \"BX-Book-Ratings.csv\", 'r', 'utf8')\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            #separate line into fields\n",
    "            fields = line.split(';')\n",
    "            user = fields[0].strip('\"')\n",
    "            book = fields[1].strip('\"')\n",
    "            rating = int(fields[2].strip().strip('\"'))\n",
    "            if user in self.data:\n",
    "                currentRatings = self.data[user]\n",
    "            else:\n",
    "                currentRatings = {}\n",
    "            currentRatings[book] = rating\n",
    "            self.data[user] = currentRatings\n",
    "        f.close()\n",
    "        #\n",
    "        # Now load books into self.productid2name\n",
    "        # Books contains isbn, title, and author among other fields\n",
    "        #\n",
    "        f = codecs.open(path + \"BX-Books.csv\", 'r', 'utf8')\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            #separate line into fields\n",
    "            fields = line.split(';')\n",
    "            isbn = fields[0].strip('\"')\n",
    "            title = fields[1].strip('\"')\n",
    "            author = fields[2].strip().strip('\"')\n",
    "            title = title + ' by ' + author\n",
    "            self.productid2name[isbn] = title\n",
    "        f.close()\n",
    "        #\n",
    "        #  Now load user info into both self.userid2name and self.username2id\n",
    "        #\n",
    "        f = codecs.open(path + \"BX-Users.csv\", 'r', 'utf8')\n",
    "        for line in f:\n",
    "            i += 1\n",
    "            #print(line)\n",
    "            #separate line into fields\n",
    "            fields = line.split(';')\n",
    "            userid = fields[0].strip('\"')\n",
    "            location = fields[1].strip('\"')\n",
    "            if len(fields) > 3:\n",
    "                age = fields[2].strip().strip('\"')\n",
    "            else:\n",
    "                age = 'NULL'\n",
    "            if age != 'NULL':\n",
    "                value = location + '  (age: ' + age + ')'\n",
    "            else:\n",
    "                value = location\n",
    "            self.userid2name[userid] = value\n",
    "            self.username2id[location] = userid\n",
    "        f.close()\n",
    "        print(i)\n",
    "                \n",
    "        \n",
    "    def pearson(self, rating1, rating2):\n",
    "        sum_xy = 0\n",
    "        sum_x = 0\n",
    "        sum_y = 0\n",
    "        sum_x2 = 0\n",
    "        sum_y2 = 0\n",
    "        n = 0\n",
    "        for key in rating1:\n",
    "            if key in rating2:\n",
    "                n += 1\n",
    "                x = rating1[key]\n",
    "                y = rating2[key]\n",
    "                sum_xy += x * y\n",
    "                sum_x += x\n",
    "                sum_y += y\n",
    "                sum_x2 += pow(x, 2)\n",
    "                sum_y2 += pow(y, 2)\n",
    "        if n == 0:\n",
    "            return 0\n",
    "        # now compute denominator\n",
    "        denominator = sqrt(sum_x2 - pow(sum_x, 2) / n) * sqrt(sum_y2 - pow(sum_y, 2) / n)\n",
    "        if denominator == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return (sum_xy - (sum_x * sum_y) / n) / denominator\n",
    "\n",
    "\n",
    "    def computeNearestNeighbor(self, username):\n",
    "        \"\"\"creates a sorted list of users based on their distance to username\"\"\"\n",
    "        distances = []\n",
    "        for instance in self.data:\n",
    "            if instance != username:\n",
    "                distance = self.fn(self.data[username], self.data[instance])\n",
    "                distances.append((instance, distance))\n",
    "        # sort based on distance -- closest first\n",
    "        distances.sort(key=lambda artistTuple: artistTuple[1], reverse=True)\n",
    "        return distances\n",
    "\n",
    "    def recommend(self, user):\n",
    "        \"\"\"Give list of recommendations\"\"\"\n",
    "        recommendations = {}\n",
    "        # first get list of users  ordered by nearness\n",
    "        nearest = self.computeNearestNeighbor(user)\n",
    "        #\n",
    "        # now get the ratings for the user\n",
    "        #\n",
    "        userRatings = self.data[user]\n",
    "        #\n",
    "        # determine the total distance\n",
    "        totalDistance = 0.0\n",
    "        for i in range(self.k):\n",
    "            totalDistance += nearest[i][1]\n",
    "        # now iterate through the k nearest neighbors\n",
    "        # accumulating their ratings\n",
    "        for i in range(self.k):\n",
    "            # compute slice of pie \n",
    "            weight = nearest[i][1] / totalDistance\n",
    "            # get the name of the person\n",
    "            name = nearest[i][0]\n",
    "            # get the ratings for this person\n",
    "            neighborRatings = self.data[name]\n",
    "            # get the name of the person\n",
    "            # now find bands neighbor rated that user didn't\n",
    "            for artist in neighborRatings:\n",
    "                if not artist in userRatings:\n",
    "                    if artist not in recommendations:\n",
    "                        recommendations[artist] = neighborRatings[artist] * weight\n",
    "                    else:\n",
    "                        recommendations[artist] = recommendations[artist] + neighborRatings[artist] * weight\n",
    "        # now make list from dictionary\n",
    "        recommendations = list(recommendations.items())\n",
    "        recommendations = [(self.convertProductID2name(k), v) for (k, v) in recommendations]\n",
    "        # finally sort and return\n",
    "        recommendations.sort(key=lambda artistTuple: artistTuple[1], reverse = True)\n",
    "        # Return the first n items\n",
    "        return recommendations[:self.n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
